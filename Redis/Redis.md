- [Redis](#redis)
- [一. 概述](#%E4%B8%80-%E6%A6%82%E8%BF%B0)
- [二. 数据类型](#%E4%BA%8C-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B)
  - [String](#string)
  - [List (列表)](#list-%E5%88%97%E8%A1%A8)
  - [set 集合](#set-%E9%9B%86%E5%90%88)
  - [hset 散列表](#hset-%E6%95%A3%E5%88%97%E8%A1%A8)
  - [zset 有序集合](#zset-%E6%9C%89%E5%BA%8F%E9%9B%86%E5%90%88)
  - [字段自增命令](#%E5%AD%97%E6%AE%B5%E8%87%AA%E5%A2%9E%E5%91%BD%E4%BB%A4)
  - [Redis 获得所有的 key 值](#redis-%E8%8E%B7%E5%BE%97%E6%89%80%E6%9C%89%E7%9A%84-key-%E5%80%BC)
- [三. Redis 持久化方式](#%E4%B8%89-redis-%E6%8C%81%E4%B9%85%E5%8C%96%E6%96%B9%E5%BC%8F)
- [四. Redis 如何于 MySQL保持数据的一致性](#%E5%9B%9B-redis-%E5%A6%82%E4%BD%95%E4%BA%8E-mysql%E4%BF%9D%E6%8C%81%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7)
  - [4.1 只读Redis](#41-%E5%8F%AA%E8%AF%BBredis)
  - [4.2 做场景划分](#42-%E5%81%9A%E5%9C%BA%E6%99%AF%E5%88%92%E5%88%86)
- [五. Redis 和 Memcached 比较](#%E4%BA%94-redis-%E5%92%8C-memcached-%E6%AF%94%E8%BE%83)
  - [5.1 数据类型](#51-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B)
  - [5.2 数据持久化](#52-%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96)
  - [5.3 分布式](#53-%E5%88%86%E5%B8%83%E5%BC%8F)
  - [5.4 内存管理机制](#54-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%9C%BA%E5%88%B6)
  - [5.5 线程模型](#55-%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B)
- [六. Redis 单线程结构](#%E5%85%AD-redis-%E5%8D%95%E7%BA%BF%E7%A8%8B%E7%BB%93%E6%9E%84)
  - [为什么单线程的条件下, 还非常的块](#%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8D%95%E7%BA%BF%E7%A8%8B%E7%9A%84%E6%9D%A1%E4%BB%B6%E4%B8%8B-%E8%BF%98%E9%9D%9E%E5%B8%B8%E7%9A%84%E5%9D%97)
- [七. Redis 的底层数据结构](#%E4%B8%83-redis-%E7%9A%84%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84)
- [八. Redis 过期时间](#%E5%85%AB-redis-%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4)
- [九. Redis 事务](#%E4%B9%9D-redis-%E4%BA%8B%E5%8A%A1)
- [十. Redis 乐观锁实现数据同步](#%E5%8D%81-redis-%E4%B9%90%E8%A7%82%E9%94%81%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5)
- [十一. Redis 底层数据结构](#%E5%8D%81%E4%B8%80-redis-%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84)
  - [散列表 (字典)](#%E6%95%A3%E5%88%97%E8%A1%A8-%E5%AD%97%E5%85%B8)
  - [跳跃表 (有序集合)](#%E8%B7%B3%E8%B7%83%E8%A1%A8-%E6%9C%89%E5%BA%8F%E9%9B%86%E5%90%88)
- [十二. Redis 过期策略](#%E5%8D%81%E4%BA%8C-redis-%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5)
  - [删除过期键对象](#%E5%88%A0%E9%99%A4%E8%BF%87%E6%9C%9F%E9%94%AE%E5%AF%B9%E8%B1%A1)
  - [内存溢出回收策略](#%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%9B%9E%E6%94%B6%E7%AD%96%E7%95%A5)
- [十三. 缓存可能存在的安全隐患](#%E5%8D%81%E4%B8%89-%E7%BC%93%E5%AD%98%E5%8F%AF%E8%83%BD%E5%AD%98%E5%9C%A8%E7%9A%84%E5%AE%89%E5%85%A8%E9%9A%90%E6%82%A3)
  - [缓存穿透](#%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F)
    - [步隆过滤器](#%E6%AD%A5%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8)



#   Redis

[TOC]



# 一. 概述	

* 速度非常快的 NoSQL 内存数据库
* 键值对的形式进行存储 (Key-Value), 其中 key 只能为字符串, Value **支持五种形式**

* Redis 支持将数据写入硬盘, 下次使用的时候, 直接从硬盘读取

* Redis 是一个 效率非常高的 **单线程 epoll 的IO多路复用模型**





# 二. 数据类型及命令

<img src='image/2019-08-01-Redis-datastruct.png' />







| 数据类型 | 可以存储的值              | 操作                                                         |
| -------- | ------------------------- | ------------------------------------------------------------ |
| STRING   | 字符串、整数或者浮点数    | 1. 对整个字符串或者字符串的其中一部分执行操作  2.  对整数和浮点数执行自增或者自减操作 |
| LIST     | 一个链表, 存的值为 字符串 | 从两端压入或者弹出元素  对单个或者多个元素进行修剪， 只保留一个范围内的元素 |
| SET      | 无序集合                  | 添加、获取、移除单个元素 检查一个元素是否存在于集合中 计算交集、并集、差集 从集合里面随机获取元素 |
| HASH     | 包含键值对的无序散列表    | 添加、获取、移除单个键值对 获取所有键值对 检查某个键是否存在 |
| ZSET     | 有序集合                  | 添加、获取、删除元素 根据分值范围或者成员来获取元素 计算一个键的排名 |



## string 

String  是 Redis 中最简单的结构

String 支持存储的数据有三类

1. 字节串 - 即字符
2. 整数
3. 浮点

String 常见的命令如下

* Set : 设置值

  ~~~shell
  # 表示 key => name 
  # value => fangzhou
  SET name fangzhou
  
  # value 之间如果有空格需要打上双引号
  SET name "fang zhou"
  
  # ❌
  SET name fang zhou
  ~~~

* Get : 获取值

  ~~~shell
  get name
  > fangzhou
  ~~~

* Del : 删除值

* 自增操作

  | cmd                     | desc                                              |
  | ----------------------- | ------------------------------------------------- |
  | INCR [key]              | 对 key 的值进行自增操作, 如果值为非整数则返回错误 |
  | DECR [key]              | 对 key 的值进行自减操作                           |
  | INCRBY [key] [num]      | 对 key 值进行增量为 num 的自增操作                |
  | DECRBY [key] [num]      | 对 key 值进行增量为 num 的自减操作                |
  | INCRBYFLOAT [key] [num] | 要求 key 的值为浮点数                             |

* 子串操作

  




## list (列表)

* 有序性 : 基于队列实现 (FIFO, 先进先出) 的结构

* 重复性: **List 允许有相同的元素出现**

有如下命令

1. 入队列

   | command                   | des                | ret                |
   | ------------------------- | ------------------ | ------------------ |
   | rpush \[list_name] [item] | List右端压入一个值 | 当前列表元素的个数 |
   | lpush [list_name] [item]  | List左端入值       | 当前列表元素的个数 |

2. 出队列

   | command              | des                  | ret  |
   | -------------------- | -------------------- | ---- |
   | rpop   [list_name]   | 从List右端取出一个值 |      |
   | lpop    \[list_name] | 从List左端取出一个值 |      |

3. 查询元素, 并不出队列

   | command                          | des                                             | ret  |
   | -------------------------------- | ----------------------------------------------- | ---- |
   | lindex \[list_name] [index]      | 从List左端以 index (索引) 查找一个值, 并不取出  |      |
   | lrange \[list_name]\[begin][end] | 从list左端查找 \[begin][end] 范围的值, 并不取出 |      |




## set 集合

* 唯一性: **和列表的区别 : 集合不允许有相同的元素出现** (通过 **散列表** 的方式实现)
* 无序性 : 使用无序的方式存储数据 (字符串) , 所以不能保证元素的取出顺序

对于集合的操作命令 :

1. 添加

   | 命令                    | 描述               | ret                     |
   | ----------------------- | ------------------ | ----------------------- |
   | sadd \[set_name] [item] | 给集合添加一个元素 | bool 表示添加 失败/成功 |

2. 查看

   | 命令                        | 描述                     | ret  |
   | --------------------------- | ------------------------ | ---- |
   | smembers [set_name]         | 显示集合的所有元素       |      |
   | sismember \[set_name][item] | 检查 item 是不是在集合中 | bool |

3. 删除

   | 命令                    | 描述                          | ret                    |
   | ----------------------- | ----------------------------- | ---------------------- |
   | srem \[set_name] [item] | 如果item 在集合中, 那么删除它 | bool 表示删除成功/失败 |





## hset 散列表 

一个微小版本的 Redis, 因为Redis就是这种 Key => Value 的形式, 而 Redis 里面的 散列表 就是存储了这样的一些键值对

<img src='image/2019-08-01-hset.png' style='width:500px'/>



命令如下 :

| 命令                               | 描述                                       |
| ---------------------------------- | ------------------------------------------ |
| hset \[hash_name] \[key] \[ value] | 在 hash_name 的表里面存储一对 key => value |
| hget [hash_name] \[key]            | 获取 hash_name 的表里面的 key 对应的 值    |
| hgetall \[hash_name]               | 获取hash_name 所有的值                     |
| hdel [hash_name] \[key]            | 删除 hash_table 里的 key => value 对       |



## zset 有序集合 

<img src ='https://github.com/CyC2018/CS-Notes/raw/master/notes/pics/1202b2d6-9469-4251-bd47-ca6034fb6116.png' style="width:400px" >



* zset 是redis中 唯一 既支持 (key => value)访问形式, 又支持顺序(index) 访问的数据结构

1. 新增命令

   | 命令                                       | 描述                                                         |
   | ------------------------------------------ | ------------------------------------------------------------ |
   | zadd \[zset_name] \[scores] \[member_name] | 给有序集合添加一个成员, 其中 排序分数[scores] 必须为 数字类型 (int , double). **插入成员的时候就按照 [scores] 排序** |

2. 查看命令

   | 命令                                                         | 描述                                                         |
   | ------------------------------------------------------------ | ------------------------------------------------------------ |
   | zrange \[zset_name] \[begin]\[end]  -[withscores]            | 查看 zset_name 中所有的member, withscores 为可选项表示 输出带有 scores. 否则只输出 member |
   | zrangebysrcore \[zset_name]  \[scores-begin] \[scores-end] -[withscores] | 按分数筛选 zset_name 里面的 member \[scores-begin] \[scores-end], 为查找分数的范围 |

3. 自增

   | cmd                        | desc                          |
   | -------------------------- | ----------------------------- |
   | ZINCRBY [zset] [num] [key] | 给zset中key元素的分数增加 num |

4. 删除命令

   | 命令                           | 描述                                          |
   | ------------------------------ | --------------------------------------------- |
   | zrem [zset_name]\[member_name] | 如果 set_name 里面有 member_name 则删除该成员 |





## 字段自增命令

Redis 支持对某个字段的自增操作

对于字段的自增操作分为两种情况  :

* **如果 value 值为 string 类型, 那么可以直接使用 INCR / INCRBY 命令**

  `INCR age` 对 `age ` 的 value 值进行自增操作, 如果值不存在, 那么初始化为 0 再执行自增

  `INCRBY age increment`  对 age 的 value 执行增量为 `increment` 的操作, 增量为负的情况下, 即为自减. 同样的, 如果不存在某个值, 则初始化为 0 再执行操作


* **如果 value 值为 HashMap, 那么需要使用 HINCRBY 命令** 

  `HINCRBY myHashSet age 10` 表示对哈希表 myHashSet 的 age 字段自增 10





## key 值匹配

通过 `Keys pattern` 的命令去实现对我们 redis 里面所有的 keys 的查询. 

**注意, 对于五种数据类型的 value 值, key 值都是通过这个命令去获得**

比如在投票场景 : 

我们可以通过 voteHashSet_voteId_userId 作为哈希表的 key 值. 在投票场景便可以通过这种方式去实现 key值查找

比如投票1的候选人hashset如下 : 

~~~
voteHashSet_1_2
voteHashSet_1_3
voteHashSet_1_4
~~~

那么我们返回所有候选者信息的时候, 就可以使用 

`keys voteHashSet_1_*` 去找到所有和这次投有关的候选人哈希表的 key 值, 从而实现遍历



## 选择数据库

Redis Select 命令用于切换到指定的数据库，数据库索引号 index 用数字值指定，以 0 作为起始索引值。

~~~shell
# index = 0, 1, 2 代表不同的数据库
redis 127.0.0.1:6379> SELECT index 
~~~

不同数据库之间数据隔离, 比如 : 

~~~shell
redis 127.0.0.1:6379> SET db_number 0         # 默认使用 0 号数据库
OK

redis 127.0.0.1:6379> SELECT 1                # 使用 1 号数据库
OK

redis 127.0.0.1:6379[1]> GET db_number        # 已经切换到 1 号数据库，注意 Redis 现在的命令提示符多了个 [1]
(nil)

redis 127.0.0.1:6379[1]> SET db_number 1
OK

redis 127.0.0.1:6379[1]> GET db_number
"1"

redis 127.0.0.1:6379[1]> SELECT 3             # 再切换到 3 号数据库
OK

redis 127.0.0.1:6379[3]>                      # 提示符从 [1] 改变成了 [3]
~~~





# 三. Redis 持久化方式

Redis 有两种方式可以将内存的数据转存到磁盘, 实现持久化存储. 

* **快照的方式(snapshotting, RDB)** :	

  在某个时间点去形成数据库中, 所有数据的副本, 然后将快照进行存储备份

* 🌟**只追加文件（append-only file, AOF）**

  这种方式为现在的主流方法, 主要思想是, 执行命令后, 将命令输出到磁盘上. 

  输出的时机有三种 : **每执行一次命令** , **一秒中执行一次** , **让系统决定**

两种方式既可以单独使用, 也可以同时使用







# 四. Redis 如何于 MySQL保持数据的一致性

Redis 作为缓存层, 如何保证和 MySQL 的一致性, 我们有如下的策略



## 4.1 只读Redis

我们可以处理数据请求时, 分为读请求和写请求:

**对于读请求 :**

如果 Redis有 , 则我们直接返回Redis的数据

**对于写请求**

我们直接写入 MySQL, 然后同步更新 Redis





## 4.2 做场景划分

对于 **实时性高的数据** 我们使用 MySQL 直接存储, 比如 : 实时的金融数据, 比分数据, 这些存入缓存也没有用

对于 **实时性较低的数据** 

1. 在并放性不高的情况下 :  我们 则经过 Redis 缓存层, 比如排行榜, 好有列表等. **读操作** 直接走Redis, **写操作** 可以 MySQL端定义CRUD触发器，在触发CRUD操作后写数据到Redis

2. 在高放性情况下 : 对于写操作, 我们可以先在 Redis 修改直接返回, 然后定期写入MySQL即可







# 五. Redis 和 Memcached 比较

两者都是非关系型内存键值数据库，主要有以下不同：



## 5.1 数据类型

Memcached 只支持字符串类型, Redis 支持五种不同的数据类型



## 5.2 数据持久化

Redis 支持两种持久化策略：RDB 快照和 AOF 日志，而 Memcached 不支持持久化。



## 5.3 分布式

* Memcached 不支持分布式, 只能自己用 一致性Hash实现
* Redis Cluster 实现了分布式的支持



## 5.4 内存管理机制 

* 在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘，而 Memcached 的数据则会一直在内存中。



## 5.5 线程模型

Memcached 是 **多线程模型, 使用的非阻塞 IO复用** 的网络模型

Redis 使用 **单线程的多路IO** 模型





# 六. Redis 单线程结构

> [Redis运行机制](https://www.jianshu.com/p/4022fbcbbc0a)

`Redis `底层使用单线程模型. 

redis单线程取到了相关套接字之后对其进行读写，这里以客户端发来set key value命令为例子，单线程读取到这个命令之后，对命令进行解析、查找命令表、调用命令对应的函数、写入数据库、返回写入结果给客户端。也就是说redis单线程除了负责读写套接字还负责执行命令的业务逻辑。除此之外redis单线程还负责调用垃圾回收函数进行垃圾回收。

也就是说, `Redis` 单线程管所有的操作, 全套服务



## 为什么单线程的条件下, 还非常的块

1. `Redis` 底层使用了一些特殊的数据结构, 比如 **跳跃表** 等等, 在存储数据结构的优化上, 让数据的存储更加的快速
2. 使用了 `IO多路复用技术` , 底层封装了四种, 选择性能最优的执行.







# 七. Redis 的底层数据结构







# 八. Redis 过期时间

我们可以自己设置一个 `key` 的过期时间, 从而 `redis `在时间到的时候, 便会自动的将其删除

那么到时间后, 将这一批 `key` 删除的策略有 

* 定期删除 :

  **定期抽取部分删**

   redis默认是每隔 100ms 就**随机抽取**一些设置了过期时间的key，检查其是否过期，如果过期就删除。注意这里是随机抽取的。为什么要随机呢？你想一想假如 redis 存了几十万个 key ，每隔100ms就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载！

* 惰性删除

  **查了删**

  定期删除可能会导致很多过期 key 到了时间并没有被删除掉。所以就有了惰性删除。假如你的过期 key，靠定期删除没有被删除掉，还停留在内存里，除非你的系统去查一下那个 key，才会被redis给删除掉。这就是所谓的惰性删除，也是够懒的哈！



# 九. Redis 事务

redis 通过 `MULTI` , `EXEC`, `WATCH` 等命令来实现事务的功能.

redis 事务一次将多个请求打包, 然后按照顺序执行多个命令的机制, 且期间不会中断去执行其他客户端的请求

在传统的事务特点 `ACID` , redis 具有  `一致性`, `隔离性`  , 但是不能保证 `原子性` , `持久性`

## `MULTI` + `EXEC`

~~~shell
# 开启事务
MULTI

# 这一系列操作会被先放入操作队列
# 然后在 EXEC 的时候一起执行
# 但是其中有一条命令执行不成功, 可能不会影响其他命令的继续执行 => 不具有 ·原子性·
set name fz
set age 20
...

# 执行事务
exec
~~~

* 事务开启时, 命令只会被放入队列, 并不实际执行, 从而也无法实时使用 `get` 操作拿到某数据的值

* 一个事务期间的所有命令处理是原子的, redis 服务端会直到处理完一个事物中所有的命令后再去处理其他客户端的请求

* 当队列中的命令出现错误的时候，可能引起队列里面的命令全部执行失败, 也可能部分失败, 因此 **redis 的事务是不具有原子性的**

  1. 编译形错误

     ~~~shell
     # 开启事务
     > multi
     
     > set name fz
     # 此时出现编译行错误, 会导致对列中的命名全部失效
     > sets age 22
     
     > exec
     ~~~

  2. 运行时错误

     ~~~shell
     > set name fz
     > set age 20
     # 开启事务
     > multi
     > set name
     # 由于 age 的数据类型并不是列表, 此时会导致运行时错误，但是之前执行的命令依然成功
     > lpush age 20
     
     > exec
     ~~~

## `WATCH`

redis 在事务中的数据访问期间是不会给数据加锁的, 这也对性能造成了极大提升

但是有些场景需要确保事务的执行期间访问的数据 **不会改变(删除, 新增, 修改)**

`WATCH` 命令有如下作用

* `WATCH k1 k2 k3 ...` 可以让 redis 在执行 `exec`命令之前, 监视 `k1, k2, ...` 如果其中一个 key 有任何改动操作, 都会引起 `exec` 命令的执行失败
* 配合 `WATCH` 命令, redis 实现了乐观锁保证了事务期间的操作值不被改变, 如果改变则执行失败后重试

## `UNWATCH`

* 该命令为 `WATCH` 的逆操作, 可以取消对与 key 值的监视
* 可以用在 `WATCH` 命令之后 `MULTI` 命令之前







# 十. Redis 乐观锁实现数据同步

`Redis` 可以利用 `Watch `+ `MULTI` + `EXEC` 组合命令的方式 去实现一个 `key` 值的同步操作

使用场景如下 , 当有两个 `Clients` 同时对 `Redis` 的某一 `key`  值操作:  

~~~shell
# Client-1
get votes 

# cilent-2
get votes


# 此时预期的结果应该是 votes 加二, 可以结果仅为加一


# client1
set votes => votes + 1

# client2
set votes => votes + 1
~~~



要解决上面的问题, 我们可以用 `Watch` + 事务的操作

~~~shell
# client1
watch votes

# 开启事务
multi

get votes 
set votes => votes + 1

# 执行
exec
~~~

此时如果 `client2` 来了之后, 如果对 `Votes` 值进行了改变, 那么这个 **事务的操作就会回滚**

**从而实现了数据的安全.**





# 十一. Redis 底层数据结构

## 散列表 (字典)

DICT 底层就是平常的 **散列表** 的数据结构, 使用拉链法解决 **Hash冲突**



## 跳跃表 (有序集合) 

**有序集合 的底层数据结构之一** 所以在 **Redis** 中 有序集合不是用 红黑树实现

跳跃表是基于 **多个有序链** 表实现的 查询过程如下: 



<img src='image/2019-09-06-JumpTable1.png' />



查找的时候, 从上层指针开始查找, 找到对应的区间到下一层去查找.

查找 **22** , 首先 **L2 到 25 超过 22 的范围, 指针下移**

<img src='image/2019-09-06-JumpTable2.png' />



和红黑树相比, 跳跃表有如下的有点 :

* 插入非常快, 因为不需要 **红黑树的自选平衡操作**
* 更容易实现
* 支持无锁操作





# 十二. Redis 过期策略

**Redis 过期回收的时间 :**

* 删除达到时间的键对象
* 内存使用达到 **Maxmemory** 上限的时候触发内存溢出控制策略



## 删除过期键对象

主要针对的是, 如何删除键过期的对象, 如果是采用的过期即删除的方式, 那么对于 **单线程的Redis** 来说维护成本比较高, 所以一般采取如下的两种方法进行删除

* 惰性删除 : 当客户端下一次调用这个 **Key-value** 的时候, 如果发现已经过期, 那么会主动的将其删除

* 定时任务删除 : 让 Redis 定时的去删除一些过去的过期的 `key-value`  

  ​	

## 内存溢出回收策略

当 **Redis** 所占用的内存满了之后, 我们便需要从内存中淘汰数据, 淘汰的策略有如下几种选择 :

* LRU 淘汰策略

* ....



# 十三. 缓存可能存在的安全隐患

## 缓存穿透

就是一直访问一个 缓存不存在的值, 同时这个值也不存在与数据库中, 从而每次的请求都会打到数据库上, 但是不会去给缓存写值, 因为根本不存在

这种攻击便为 **缓存穿透**



### 步隆过滤器

> [步隆过滤器](<https://www.jianshu.com/p/2104d11ee0a2>)



当一个key值不在 redis的时候, 我们只需要去判断 这个要查询的值是否存在于我们的 mysql 中即可.

如何去判断就是采用了我们的 **布隆过滤器** 的一个思想

数据库中, 所有的



# 十四. 高级数据类型

## BitMpas 位图

一串二进制, 可以以bit为维度操作该结构, 适用于可以将记录ID表示为唯一的偏移量, 且只有两种属性的场景(0/1)

| cmd                                | desc                                  | ret  |
| ---------------------------------- | ------------------------------------- | ---- |
| setbit [key] [offset] [value(0/1)] | 将位图offset的位置的值置为指定        |      |
| getbit [key] [offset]              | 获取位图offset处的偏移量              |      |
| bitcount [key] [start] [end]       | 统计偏移量从 start 到 end 为 1 的总数 |      |

使用场景:

如记录用户ID一天是否登录, 则可以使用用户ID作为 offset, 登录一次后将其置为1, 每天结束后, 即可以使用 `bitcount` 统计一天登陆的用户数量



## HyperLogLog

* 不存储具体值, 只会输出独立ID出现的总次数
* 采用统计伯努利算法, 会出现大概 0.81% 左右的误差, 但是一个 HpyerLogLog 只占用大概 12k 内存

海量数据去重统计, 可以记录数据中不同ID的出现总次数

| cmd                       | desc                              | ret  |
| ------------------------- | --------------------------------- | ---- |
| pfadd [key] [v1, v2, ...] | 将hyperLogLog添加 v1, v2 这些元素 |      |
| pfcount [key]             | 统一不同元素出现的次数            |      |
| pfmerge [key1]  [key2]    | 合并两个hyperLogLog               |      |

~~~shell
#
pfadd pf 1 1 2 2 3 4

# ID分别为 1,2,3,4 共出现4次
pfcount pf
> 4
~~~

使用场景:

统计一个网站的 UV, 即一天网站访问的独立用户量





# 十五. Redis 高可用方案

> [Redis分布式高可用指南](https://www.jianshu.com/p/21110d3130bc)

## Redis Sentinel

基本架构

* redis svr 采用主从架构部署, **主服务器定期同步数据到从服务器**
* 使用哨兵机制监控 **主, 从 redis svr 的健康状态** 如果主服务器不可用, 哨兵还会选举出新的主服务器
* 哨兵将作为代理替代客户端直连 redis svr
* 哨兵水平扩展部署, 同时也相互监控健康状态

### Redis 哨兵服务器

redis 哨兵从本质上来说就是一个特殊的 redis 服务器, 可以通过正常的 redis 启动来指定哨兵属性

~~~shell
# 哨兵模式启动一个redis svr
$redis-server xxx/sentinel.conf --sentinel
~~~

哨兵svr和普通svr区别如下

1. 哨兵svr不需要存储数据, 因此其不需要在初始化的时候读取 RDB 或者 AOF 文件重载数据
2. 哨兵svr支持的客户端命令也和普通svr有所不同, 对于普通的存储命令, 哨兵svr都不支持



### Redis 哨兵和 master svr 通信

哨兵在初始化的时候会默认和集群的 redis master svr  建立连接 (命令连接 + 订阅连接), 并会以默认 10 秒一次的频率通过命令连接对主服务器发送 `INFO` 命令来分析其当前的状态, 通过 `INFO` 命令可以返回的信息有

1. 主服务器本身信息
2. 主服务器下所有从服务器的信息

哨兵会根据这些信息存储一份该改主服务器的所有从服务器字典



### Redis哨兵检测节点是否在线

哨兵通过 1s 一次的 `PING`命令 (此 PING 为Redis内部命令), 向 主, 从, 其他哨兵 发送启动来判断对方是否在线

1. 如果 svr 端的返回不符合预期, 则会 **主观** 的判断此时的 svr 已经下线
2. 此时哨兵还会去和其他哨兵通信确定此 svr 是否下线, **当有足够多的哨兵都认为下线时** 此svr则会被判定为 **客观下线**



### Redis 重新选举 master svr及故障迁移

当哨兵发现 master svr 客观下线时, 会发起 master svr 重新选举的过程, 大致流程如下

1. 选举出一个 **领头哨兵** , 选举规则如下

   * 所有的哨兵都有机会成为 **领头哨兵**
   * 在一个 **配置纪元** 所有的哨兵都有资格设置某一个哨兵为 **局部领头哨兵**, 且设置后不可再更改
   * 每个发现 **master svr客观下线** 的哨兵都会要求其他哨兵 **将自己设置为局部领头哨兵**
   * 在一个 **配置纪元, 局部领头哨兵的资格先到先得**
   * 当一个 局部领头哨兵或者 **超过半数** 哨兵的支持时, 其会变为 **全局领头哨兵**, 负责master svr 的故障迁移工作

2. 由 **领头哨兵重新挑选 master svr**, 挑选规则如下

   * 选择列表保证都是 **在线状态** 的从服务器
   * 选择列表保证都是在 5s 内和领头哨兵通信过的从服务器
   * 选择数据最新的一个从服务器(即与下线主服务器通信时间最近)

3. 故障迁移

   * 通过 `SLAVEOF no one` 将其置为新的 master svr

   * 通过 `SLAVEOF` 命令将所有的旧从服务器发送新主服务的复制命令并更改归属
   * 如果故障中的服务器恢复则会被自动降级为从服务器

## Redis Cluster

Redis-Cluster 是官方实现的另一种高可用方案, 解决空间浪费的问题, 每个节点 **分片存储数据**

基本架构

* 将整块数据分为 16384 个槽位, 每个 redis-svr 节点存储一段槽位的数据, 例如此时有三个节点

  `Redis1 -> [0, 5461]`,  `redis2 -> [5462, 10922]`,  `redis3 -> [10923, 16384]`

  当有数据请求时先计算 `CRC16(key)%16384 ` 计算该key的槽归属, 再请求对应的节点获取数据

* redis-cluster 模式下的主备是基于节点的, 例如可以给上述 redis1-svr 节点分配多个从服务器, 专门用于同步 [0, 5461]的槽数据

* 主备模式主节点负责读/写操作, 从节点负责读操作

### 集群结构

一个 redis 集群由多个节点构成, 每个节点除了存储 redis svr 基本的信息之外, 还会用三个数据结构存储集群有关的数据结构, 分别如下

* `clusterNode`

  存储本节点的一些基本信息

* `clusterLink`

  存储本节点和集群其他节点的连接信息, 包括通信缓冲区等

* `clusterState`

  存储本节点视角下集群的信息, 如当前配置纪元, 集群是否在线, 集群其他节点信息等

初始状态下, 每个节点都是一个单集群, 可以通过 `cluster meet <ip> <port>` 命令增加集群节点

如在 A 节点 cli 通过 `cluster meet` 添加 B 节点, 则大致会生以下事件

* A 节点会在自己的 `clusterState.nodes` 结构中存储 B 节点的相关信息
* A 节点向 B 节点发送 `meet` 信号
* B 节点在自己的 `clsuterState.nodes` 结构中存储 A 节点的相关信息
* B 节点返回 `PONG` 信号
* A 节点返回 `PINT` 信号完成握手

### 数据分片 - 槽指派

集群中的数据库会被分配 **16384** 个数据槽, 只有当所有数据槽都有节点处理时, 集群才处于上线状态

可以通过在节点 cli 上 `cluster addslots [...] ` 对该节点分配数据槽

节点的 `clusterNode.slots` 结构会存该节点负责处理的槽信息

~~~c++
struct clusterNode {
  
  // slots 相当于一个bitmap, 通过 0/1 表示 offset 的槽是否归该节点处理
  unsigned char slots[16384/8];
  
  // slots 为1的位总数, 即负责处理槽的数量
  int numslots;
}
~~~



### 槽归属信息传播

集群之间的节点会相互通信交换自己负责的槽信息, 节点的 `clusterState.nodes` 结构中则会记录集群中所有的节点负责的槽信息.

**即每个节点都会存储一份集群中全量槽的指派信息**, 存储方式如下

~~~c++
struct clusterState {
  	
   // slots 数据存储的全量槽的归属节点指针
   // 可以将查询槽归属的时间复杂度降为O(1)
   clusterNode *slots[16384];
  
   // 集群的节点名单, 会指向 clusterNode 结构体
   // 每个节点体也会存储当前节点负责的 slots 数组信息
	 dict *nodes;
}
~~~



### 根据 Key 值计算其槽归属

节点通过 **CRC16** 算法可以计算出给定的 key 值的槽归属

~~~python
def slot_number(key):
    return CRC16(key) & 16383
~~~



### 重新分片

redis 可以对某些槽的值信息迁移, 具体步骤如下

* `redis-trib` 对目标集群发送准备迁移命令

  ~~~sh
  # 该命令让slot的原始归属槽准备迁移工作
  $cluster setslot <slot> importing <source_ip>
  ~~~

* 获取该槽下的所有 key

  ~~~shell
  $cluster getkeysinslot <slot> <count>
  ~~~

* 根据返回的key值发送 `migrate` 命令执行迁移

重新分片过程中,  可能出现 **ASK 错误**, 具体场景是, 客户端查询的key值正好处于在迁移的槽中

* 如果该key还没有被迁移, 则直接返回对应 value
* 如果该key已经被迁移, 则返回 **ASK错误**, 被重定向到新主机中



### 复制与故障转移

每个集群节点可以指定其附属的从节点作复制操作, 从节点负责复制主节点归属槽位内的数据, 当主节点发生故障时. 会重新在从节点中选举新的主节点做故障转移

1. 集群主节点故障检测的步骤大致如下
   * 集群每个节点会定期向每个节点发送 `PING` 信号, 当某节点超过一定时间没有回复时, 会将其标记为 **疑似下线状态**,
   * 该节点会询问集群中其他节点, 该节点是否下线, 如果 **超过半数**的节点都认为其处于下线状态, 则会开始故障转移工作

2. 选举新的主节点
   * 选举的 **投票权在集群中所有主节点** 上
   * 一个配置纪元中, 主节点最多只有一次投票的机会
   * 如果一个从节点发现其主节点发生故障, 则会广播一条消息要求所有主节点为其投票
   * 如果一个从节点获取 **半数以上** 的选票, 则会当选为新的主节点
3. 故障转移
   * 当新的主节点当选后, 会将其自己置为主节点, 且广播消息
   * 将其与所有从节点置为自己的主节点

























































 